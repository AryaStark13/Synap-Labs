{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate, load_prompt\n",
    "from langchain.agents import load_tools, initialize_agent\n",
    "import openai\n",
    "import os\n",
    "import wandb\n",
    "from wandb.integration.langchain import WandbTracer\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33marihantsheth\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\ariha\\Desktop\\Synap Labs\\notebooks\\wandb\\run-20230614_122250-ih7v5lcu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/arihantsheth/generate_simple_prd/runs/ih7v5lcu' target=\"_blank\">generate_simple_prd_v2</a></strong> to <a href='https://wandb.ai/arihantsheth/generate_simple_prd' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/arihantsheth/generate_simple_prd' target=\"_blank\">https://wandb.ai/arihantsheth/generate_simple_prd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/arihantsheth/generate_simple_prd/runs/ih7v5lcu' target=\"_blank\">https://wandb.ai/arihantsheth/generate_simple_prd/runs/ih7v5lcu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/arihantsheth/generate_simple_prd/runs/ih7v5lcu?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x275f9789d20>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    project=\"generate_simple_prd\",\n",
    "    config={\n",
    "        \"model\": \"gpt-3.5-turbo\",\n",
    "        \"temperature\": 0\n",
    "    },\n",
    "    entity=\"arihantsheth\",\n",
    "    name=\"generate_simple_prd_v2\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ariha\\Desktop\\Synap Labs\\synap_labs_env\\lib\\site-packages\\langchain\\llms\\openai.py:171: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "c:\\Users\\ariha\\Desktop\\Synap Labs\\synap_labs_env\\lib\\site-packages\\langchain\\llms\\openai.py:740: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "llm = OpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "prompt_template = load_prompt(\"../prompt_templates/generate_prd_template_v2.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_input_variables = {\n",
    "    \"wandb\": dict(\n",
    "        new_feature=\"Model Explainability Toolkit (MXT)\",\n",
    "        new_feature_desc=\"Enables users to interpret and explain the outputs and decision-making of their AI Models.\"\n",
    "    ),\n",
    "    \"langchain\": dict(\n",
    "        new_feature=\"Model Training Wizard (MTW)\",\n",
    "        new_feature_desc=\" A user-friendly interface that guides users through the process of training their own custom language models. It would provide step-by-step instructions, dataset management tools, and performance evaluation metrics to help users create high-quality models tailored to their specific needs.\"\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_template = \"\"\"\\\n",
    "You are a talkative product manager.\n",
    "\n",
    "Now, you want to add the following new feature to this:\n",
    "{new_feature}\n",
    "Feature description: {new_feature_desc}\n",
    "\n",
    "Create a Product Requirement Document (PRD) to add this new feature in the following format. Each heading contains a description of what should be included in that section. Return your output in a markdown format to maintain consistency:\n",
    "\n",
    "1. What Are We Solving For?\n",
    "    Give the high-level reasoning for this proposal. What is the problem or opportunity we’re pursuing? Who is this for? What segments or personas are impacted?\n",
    "\n",
    "2. Why Does It Matter?\n",
    "    Why is this initiative big enough to matter to Customers? What data or studies do we have to support this? \n",
    "\n",
    "3. What Does Success Look Like?\n",
    "    What is the primary metric you’ll use to gauge success of this initiative? What is the target lift/impact to this metric, over what time period?\n",
    "    What are the secondary metric(s) of success?\n",
    "\n",
    "4. Background\n",
    "    Include any necessary background research here, including data analysis, industry research, competitor analysis, quantitative or qualitative customer insights, etc.\n",
    "\n",
    "5. Known Constraints\n",
    "    Where applicable, lay out any constraints that must be taken into account when designing a solution. These constraints may related to usability (i.e. accessibility), time (seasonality), technology (platform capabilities or site performance), legal, and business guardrails. \n",
    "\n",
    "6. Solution Proposal\n",
    "    Given the opportunity, the background, and the constraints, what are we proposing? List bullet points or insert sketches that describe the solution at a high level. If this initiative is successful, what will get better for the customers?\n",
    "\n",
    "7. Risks & Assumptions\n",
    "    What must we assume to be true in order for this initiative to be successful? What developments could cause this initiative to be unsuccessful? Risks include fraud/abuse potential, security…\n",
    "\n",
    "8. Target Customers\n",
    ">   8.1 Market\n",
    "        Detail the specific regions & countries which the Product Development Team needs to build a solution for? Where we can lean into opportunities? Where do we need to mitigate emergent risks?\n",
    ">   8.2 Audience Segments\n",
    "        List the unique customer audiences this solution needs to address uniquely. \n",
    "\n",
    "9. User Experience\n",
    ">   9.1 User Flows\n",
    "        What screens, touch points or experiences that are being considered as part of this initiative? There may be several - and these may cross boundaries of products, experiences and user states. \n",
    "\n",
    "10. High Level Use Cases: Fill it in the given format\n",
    "\n",
    "|    \t| Name                                                       \t| Description                                                                                                                                            \t| PDT or Squad                                                                           \t| Dependency?                                                                 \t| Priority                                    \t| Open Questions,  Notes & Discussions                                             \t|\n",
    "|----\t|------------------------------------------------------------\t|--------------------------------------------------------------------------------------------------------------------------------------------------------\t|----------------------------------------------------------------------------------------\t|-----------------------------------------------------------------------------\t|---------------------------------------------\t|----------------------------------------------------------------------------------\t|\n",
    "| Desc  | Give this use case a name. e.g. Order Lifecycle Management \t| Note: this is not a user story. User stories are much more detailed/granular views of use cases. They represent the requirements & definition of done. \t| Name the Product Development team or squad if you know who will work on this use case. \t| If this use case has a dependency, list the use case # on which it depends. \t| MUST HAVE SHOULD HAVE COULD HAVE WON'T HAVE \t| Important things team members should know / things you're working to figure out. \t|\n",
    "\n",
    "11. Rollout Approach\n",
    "    How will we execute this rollout? Big-bang or gradual scale-up? A/B test or launch-and-measure? \n",
    "    Will the rollout happen in every market at once, or will markets ramp up one by one?\n",
    "    Be inclusive of other key Product Development Team members in having this discussion, in particular Data Analysts, Data Science and Business Ops, along with Developers.\n",
    "    Provide a comprehensive view into the Pros/Cons, what can/cannot be answered as a result, and reasoning behind the decision being made for the rollout approach. \n",
    "\n",
    "12. Measuring Success\n",
    "    If A/B testing, describe the variants being tested, traffic allocations to each variant, and the KPIs being measured in the experiment. \n",
    "    Describe the desired cadence of performance readouts and align with Analytics to ensure it’s covered.\n",
    "    As with the Rollout Approach section, please be sure to socialize this plan with your partners in Analytics, Data Science and Business Operations.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt_template = PromptTemplate(template=string_template, input_variables=[\"new_feature\", \"new_feature_desc\"])\n",
    "\n",
    "# prompt_template.save(\"../prompt_templates/generate_prd_template_v2.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = dict()\n",
    "for company in prompt_input_variables:\n",
    "    prompts[company] = prompt_template.format(**prompt_input_variables[company])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../company_prompts/prompt_inputs_v2.json\", \"w\") as f:\n",
    "    json.dump(prompt_input_variables, f)\n",
    "\n",
    "with open(\"../company_prompts/prompts_v2.json\", \"w\") as f:\n",
    "    json.dump(prompts, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating PRD for wandb...\n",
      "Generating PRD for langchain...\n"
     ]
    }
   ],
   "source": [
    "outputs = dict()\n",
    "\n",
    "for company in prompts:\n",
    "    print(f\"Generating PRD for {company}...\")\n",
    "    prompt = prompts[company]\n",
    "    \n",
    "    try:\n",
    "        # output = llm(prompt, callbacks=[WandbTracer()])\n",
    "        output = llm(prompt)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        output = f\"ERROR: {e}\"\n",
    "\n",
    "    outputs[company] = output\n",
    "    # wandb.log({f\"{company}_prd\": output})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRD for wandb:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# Model Explainability Toolkit (MXT) Feature PRD\n",
       "\n",
       "## 1. What Are We Solving For?\n",
       "We are proposing to add a new feature to the Model Explainability Toolkit (MXT) that enables users to interpret and explain the outputs and decision-making of their AI Models. This feature aims to address the problem of lack of transparency and interpretability in AI models, which can hinder user trust and adoption. The target audience for this feature includes data scientists, machine learning engineers, and AI practitioners who want to gain insights into how their models make decisions.\n",
       "\n",
       "## 2. Why Does It Matter?\n",
       "This initiative is significant because it empowers customers to understand and explain the outputs and decision-making of their AI models. By providing interpretability and explainability, users can gain insights into the factors influencing their models' predictions, identify biases or errors, and build trust with stakeholders. Studies have shown that interpretability is crucial for regulatory compliance, ethical considerations, and user acceptance of AI models.\n",
       "\n",
       "## 3. What Does Success Look Like?\n",
       "The primary metric to gauge the success of this initiative is the increase in user satisfaction with model interpretability. We aim to achieve a target lift of 20% in user satisfaction within 6 months of launching the feature. The secondary metrics of success include an increase in user engagement with the MXT feature, a decrease in user-reported issues related to model interpretability, and positive feedback from users regarding the usefulness of the feature.\n",
       "\n",
       "## 4. Background\n",
       "Extensive research and industry analysis have highlighted the importance of model interpretability and explainability. Many AI models, such as deep neural networks, are often considered black boxes due to their complex architectures and lack of transparency. This can lead to challenges in understanding how models arrive at their predictions, making it difficult to trust and validate their outputs. Competitors in the market have started offering similar explainability features, and customer feedback indicates a strong demand for interpretability tools.\n",
       "\n",
       "## 5. Known Constraints\n",
       "- Usability: The solution should be designed to be user-friendly and accessible to users with varying levels of technical expertise.\n",
       "- Time: The solution should be developed and launched within 6 months to meet market demand and stay ahead of competitors.\n",
       "- Technology: The solution should leverage existing platform capabilities and ensure optimal site performance.\n",
       "- Legal: The solution should comply with relevant data privacy and security regulations.\n",
       "- Business: The solution should align with the company's strategic goals and financial constraints.\n",
       "\n",
       "## 6. Solution Proposal\n",
       "- Develop an intuitive user interface within the MXT platform that allows users to visualize and explore the decision-making process of their AI models.\n",
       "- Provide feature importance rankings, highlighting the most influential factors in the model's predictions.\n",
       "- Enable users to drill down into individual predictions to understand the specific factors that contributed to each decision.\n",
       "- Offer model-agnostic interpretability techniques, such as LIME and SHAP, to accommodate a wide range of AI models.\n",
       "- Provide explanations in both textual and graphical formats to cater to different user preferences.\n",
       "- Improve the documentation and user guides to educate users on the importance of model interpretability and how to effectively use the MXT feature.\n",
       "\n",
       "If this initiative is successful, customers will have a better understanding of their AI models' decision-making process, leading to increased trust, improved model performance, and enhanced compliance with regulatory requirements.\n",
       "\n",
       "## 7. Risks & Assumptions\n",
       "Risks:\n",
       "- The interpretability techniques may not be applicable to all types of AI models, requiring additional research and development efforts.\n",
       "- The explanations provided by the MXT feature may not always align with users' expectations, leading to potential user dissatisfaction.\n",
       "- Ensuring the security and privacy of the model's internal workings and data used for explanations is crucial to mitigate potential risks of unauthorized access or misuse.\n",
       "\n",
       "Assumptions:\n",
       "- Users have a basic understanding of machine learning concepts and are willing to invest time in interpreting and explaining their models.\n",
       "- The MXT feature will be well-received by users and positively impact their workflow and decision-making processes.\n",
       "\n",
       "## 8. Target Customers\n",
       "### 8.1 Market\n",
       "The Product Development Team needs to build a solution for the global market, with a focus on regions and countries where AI adoption is high, such as the United States, Europe, and Asia. Opportunities can be leveraged in emerging markets where AI adoption is growing rapidly. Risks related to regulatory compliance and data privacy should be mitigated by ensuring the solution aligns with local laws and regulations.\n",
       "\n",
       "### 8.2 Audience Segments\n",
       "- Data scientists and machine learning engineers who develop and deploy AI models.\n",
       "- AI practitioners who need to explain and justify the decisions made by their models to stakeholders.\n",
       "- Compliance officers and auditors who require transparency and interpretability in AI models for regulatory purposes.\n",
       "\n",
       "## 9. User Experience\n",
       "### 9.1 User Flows\n",
       "- User logs into the MXT platform and selects the AI model they want to interpret.\n",
       "- User navigates to the \"Explainability\" section and chooses the desired interpretability technique.\n",
       "- User explores the feature importance rankings and drills down into individual predictions for detailed explanations.\n",
       "- User can customize the visualization and export the explanations for reporting or further analysis.\n",
       "- User can access comprehensive documentation and tutorials to learn how to effectively interpret and explain their models.\n",
       "\n",
       "## 10. High Level Use Cases:\n",
       "\n",
       "|    \t| Name                                                       \t| Description                                                                                                                                            \t| PDT or Squad                                                                           \t| Dependency?                                                                 \t| Priority                                    \t| Open Questions,  Notes & Discussions                                             \t|\n",
       "|----\t|------------------------------------------------------------\t|--------------------------------------------------------------------------------------------------------------------------------------------------------\t|----------------------------------------------------------------------------------------\t|-----------------------------------------------------------------------------\t|---------------------------------------------\t|----------------------------------------------------------------------------------\t|\n",
       "| 1 \t| Feature Importance Ranking                                 \t| Provide users with a ranked list of the most important features influencing the model's predictions.                                                 \t| MXT Development Team                                                                    \t| -                                                                           \t| MUST HAVE                                    \t| -                                                                                \t|\n",
       "| 2 \t| Individual Prediction Explanation                          \t| Enable users to explore the factors contributing to individual predictions made by the model.                                                        \t| MXT Development Team                                                                    \t| -                                                                           \t| MUST HAVE                                    \t| -                                                                                \t|\n",
       "| 3 \t| Model-Agnostic Interpretability Techniques                 \t| Implement popular interpretability techniques like LIME and SHAP that can be applied to a wide range of AI models.                                   \t| MXT Development Team                                                                    \t| -                                                                           \t| SHOULD HAVE                                  \t| -                                                                                \t|\n",
       "| 4 \t| Customizable Visualization                                 \t| Allow users to customize the visualization of explanations based on their preferences and reporting requirements.                                    \t| MXT Development Team                                                                    \t| -                                                                           \t| SHOULD HAVE                                  \t| -                                                                                \t|\n",
       "| 5 \t| Documentation and Tutorials                                \t| Improve the documentation and user guides to educate users on the importance of model interpretability and how to effectively use the MXT feature.   \t| MXT Development Team                                                                    \t| -                                                                           \t| SHOULD HAVE                                  \t| -                                                                                \t|\n",
       "\n",
       "## 11. Rollout Approach\n",
       "The rollout approach for this feature will involve a gradual scale-up. We will initially launch the feature as a beta version to a select group of users, including existing customers who have expressed interest in interpretability tools. This will allow us to gather feedback, identify any potential issues, and make necessary improvements before a full-scale launch. The rollout will happen in multiple markets simultaneously to ensure a global reach and maximize user adoption. A/B testing will be conducted to measure the impact of the feature on user satisfaction and engagement.\n",
       "\n",
       "## 12. Measuring Success\n",
       "A/B testing will be conducted to compare the performance of the MXT feature with and without the new interpretability capabilities. The variants being tested include the control group (without the feature) and the experimental group (with the feature). Traffic allocation will be evenly split between the two groups. The primary KPIs being measured in the experiment include user satisfaction, user engagement, and user-reported issues related to model interpretability. Performance readouts will be conducted on a monthly basis, and the results will be shared with the Analytics, Data Science, and Business Operations teams for further analysis and insights."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "for company in outputs:\n",
    "    print(f\"PRD for {company}:\")\n",
    "    display(Markdown(outputs[company]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for company in outputs:\n",
    "    with open(f\"../generated_prds/{company}_prd_v2.md\", \"w\") as f:\n",
    "        f.write(outputs[company])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>langchain_prd</td><td># Langchain Model Tr...</td></tr><tr><td>wandb_prd</td><td># Product Requiremen...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">generate_simple_prd_v2</strong> at: <a href='https://wandb.ai/arihantsheth/generate_simple_prd/runs/ih7v5lcu' target=\"_blank\">https://wandb.ai/arihantsheth/generate_simple_prd/runs/ih7v5lcu</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230614_122250-ih7v5lcu\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "synap_labs_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
