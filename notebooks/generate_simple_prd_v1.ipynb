{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate, load_prompt\n",
    "from langchain.agents import load_tools, initialize_agent\n",
    "import openai\n",
    "import os\n",
    "import wandb\n",
    "from wandb.integration.langchain import WandbTracer\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33marihantsheth\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\ariha\\Desktop\\Synap Labs\\wandb\\run-20230607_145401-uj84b0gm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/arihantsheth/generate_simple_prd/runs/uj84b0gm' target=\"_blank\">generate_multiple_prd_1</a></strong> to <a href='https://wandb.ai/arihantsheth/generate_simple_prd' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/arihantsheth/generate_simple_prd' target=\"_blank\">https://wandb.ai/arihantsheth/generate_simple_prd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/arihantsheth/generate_simple_prd/runs/uj84b0gm' target=\"_blank\">https://wandb.ai/arihantsheth/generate_simple_prd/runs/uj84b0gm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/arihantsheth/generate_simple_prd/runs/uj84b0gm?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x1ecaa148400>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    project=\"generate_simple_prd\",\n",
    "    config={\n",
    "        \"model\": \"gpt-3.5-turbo\",\n",
    "        \"temperature\": 0\n",
    "    },\n",
    "    entity=\"arihantsheth\",\n",
    "    name=\"generate_multiple_prd_1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ariha\\Desktop\\Synap Labs\\synap_labs_env\\lib\\site-packages\\langchain\\llms\\openai.py:171: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "c:\\Users\\ariha\\Desktop\\Synap Labs\\synap_labs_env\\lib\\site-packages\\langchain\\llms\\openai.py:740: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "llm = OpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "prompt_template = load_prompt(\"./prompt_templates/generate_prd_template.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_input_variables = {\n",
    "    \"wandb\": dict(\n",
    "        new_feature=\"Model Explainability Toolkit (MXT)\",\n",
    "        new_feature_desc=\"Enables users to interpret and explain the outputs and decision-making of their AI Models.\"\n",
    "    ),\n",
    "    \"langchain\": dict(\n",
    "        new_feature=\"Model Training Wizard (MTW)\",\n",
    "        new_feature_desc=\" A user-friendly interface that guides users through the process of training their own custom language models. It would provide step-by-step instructions, dataset management tools, and performance evaluation metrics to help users create high-quality models tailored to their specific needs.\"\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_template = \"\"\"\\\n",
    "You are a talkative product manager.\n",
    "\n",
    "Now, you want to add the following new feature to this:\n",
    "{new_feature}\n",
    "Feature description: {new_feature_desc}\n",
    "\n",
    "Create a Product Requirement Document (PRD) to add this new feature in the following format:\n",
    "\n",
    "1. Project Overview: An introduction to the project, its purpose, and the problem it aims to solve.\n",
    "\n",
    "2. Project Scope: A detailed description of what is included and excluded from the project.\n",
    "\n",
    "3. Functional Requirements: Specific features and functionalities that the project should deliver.\n",
    "\n",
    "4. Non-functional Requirements: Criteria related to performance, security, usability, scalability, etc.\n",
    "\n",
    "5. Use Cases: Detailed scenarios that describe how users will interact with the product.\n",
    "\n",
    "6. User Interface (UI) and User Experience (UX) Guidelines: Design principles and requirements for the user interface.\n",
    "\n",
    "7. Assumptions and Constraints: Factors or limitations that may impact the project's development or implementation.\n",
    "\n",
    "8. Technical Requirements: Any specific technologies, platforms, or infrastructure required for the project.\n",
    "\n",
    "9. Timeline and Milestones: A proposed schedule or timeline for the project, including key milestones and deliverables.\n",
    "\n",
    "10. Success Criteria: Criteria for evaluating the success of the project and how it aligns with the overall business goals.\n",
    "\n",
    "11. Customer analysis: An analysis of customers who would actually use this feature. \n",
    "\n",
    "Return your output in a markdown format to maintain consistency.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt_template = PromptTemplate(template=string_template, input_variables=[\"new_feature\", \"new_feature_desc\"])\n",
    "\n",
    "prompt_template.save(\"../prompt_templates/generate_prd_template_v1.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = dict()\n",
    "for company in prompt_input_variables:\n",
    "    prompts[company] = prompt_template.format(**prompt_input_variables[company])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../company_prompts/prompt_inputs.json\", \"w\") as f:\n",
    "    json.dump(prompt_input_variables, f)\n",
    "\n",
    "with open(\"../company_prompts/prompts.json\", \"w\") as f:\n",
    "    json.dump(prompts, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating PRD for wandb...\n",
      "Generating PRD for langchain...\n"
     ]
    }
   ],
   "source": [
    "outputs = dict()\n",
    "\n",
    "for company in prompts:\n",
    "    print(f\"Generating PRD for {company}...\")\n",
    "    prompt = prompts[company]\n",
    "    \n",
    "    try:\n",
    "        # output = llm(prompt, callbacks=[WandbTracer()])\n",
    "        output = llm(prompt)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        output = f\"ERROR: {e}\"\n",
    "\n",
    "    outputs[company] = output\n",
    "    # wandb.log({f\"{company}_prd\": output})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for company in outputs:\n",
    "    with open(f\"./generated_prds/{company}_prd.md\", \"w\") as f:\n",
    "        f.write(outputs[company])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>langchain_prd</td><td># Product Requiremen...</td></tr><tr><td>wandb_prd</td><td># Product Requiremen...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">generate_multiple_prd_1</strong> at: <a href='https://wandb.ai/arihantsheth/generate_simple_prd/runs/uj84b0gm' target=\"_blank\">https://wandb.ai/arihantsheth/generate_simple_prd/runs/uj84b0gm</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230607_145401-uj84b0gm\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Product Requirement Document (PRD)\n",
       "\n",
       "## 1. Project Overview:\n",
       "The Model Explainability Toolkit (MXT) is a project aimed at enabling users to interpret and explain the outputs and decision-making of their AI Models. The purpose of this project is to provide users with a tool that enhances their understanding of AI models, allowing them to gain insights into the reasoning behind the model's predictions. By addressing the lack of transparency in AI models, MXT aims to increase trust and confidence in AI systems.\n",
       "\n",
       "## 2. Project Scope:\n",
       "The project includes the development of a toolkit that integrates with existing AI models and provides users with interpretability and explanation capabilities. The toolkit will support various types of AI models and will be compatible with popular frameworks and platforms. However, the project does not involve the development of new AI models or modifications to the existing models.\n",
       "\n",
       "## 3. Functional Requirements:\n",
       "- Integration: The toolkit should be able to integrate with different AI models and frameworks.\n",
       "- Interpretability Metrics: Provide users with interpretability metrics to quantify the transparency of AI models.\n",
       "- Feature Importance: Enable users to identify and understand the importance of different features in the model's decision-making process.\n",
       "- Rule Extraction: Allow users to extract rules or decision trees from the AI model to gain insights into its decision-making process.\n",
       "- Visualization: Provide visualizations to help users understand and interpret the outputs of the AI model.\n",
       "- Explanation Generation: Generate explanations for individual predictions made by the AI model, highlighting the key factors that influenced the decision.\n",
       "\n",
       "## 4. Non-functional Requirements:\n",
       "- Performance: The toolkit should have minimal impact on the performance of the AI models.\n",
       "- Security: Ensure the security and privacy of the AI models and their data.\n",
       "- Usability: The toolkit should be user-friendly and intuitive, requiring minimal technical expertise.\n",
       "- Scalability: The toolkit should be able to handle large-scale AI models and datasets efficiently.\n",
       "\n",
       "## 5. Use Cases:\n",
       "- Use Case 1: A data scientist wants to understand why an AI model classified a particular image as a cat and wants to visualize the important features that contributed to the decision.\n",
       "- Use Case 2: A compliance officer needs to explain the decision-making process of an AI model to meet regulatory requirements and ensure transparency.\n",
       "- Use Case 3: An AI model developer wants to compare the interpretability of different models to choose the most transparent one for a specific use case.\n",
       "\n",
       "## 6. User Interface (UI) and User Experience (UX) Guidelines:\n",
       "- The UI should be intuitive and provide clear navigation to different interpretability features.\n",
       "- Visualizations should be interactive and allow users to explore different aspects of the model's decision-making process.\n",
       "- Explanations should be presented in a concise and understandable manner, avoiding technical jargon.\n",
       "\n",
       "## 7. Assumptions and Constraints:\n",
       "- The toolkit assumes that users have access to trained AI models and their corresponding datasets.\n",
       "- The interpretability provided by the toolkit is based on the characteristics and limitations of the underlying AI models.\n",
       "\n",
       "## 8. Technical Requirements:\n",
       "- The toolkit should be compatible with popular AI frameworks such as TensorFlow, PyTorch, and scikit-learn.\n",
       "- It should support both on-premises and cloud-based deployment options.\n",
       "- The toolkit should be able to handle different types of AI models, including deep learning models, decision trees, and ensemble models.\n",
       "\n",
       "## 9. Timeline and Milestones:\n",
       "- Milestone 1: Requirements gathering and analysis - 2 weeks\n",
       "- Milestone 2: Development of interpretability metrics and feature importance - 4 weeks\n",
       "- Milestone 3: Rule extraction and visualization - 6 weeks\n",
       "- Milestone 4: Explanation generation and UI development - 4 weeks\n",
       "- Milestone 5: Testing and bug fixing - 2 weeks\n",
       "\n",
       "## 10. Success Criteria:\n",
       "- The toolkit should provide users with meaningful and accurate interpretability insights for their AI models.\n",
       "- Users should be able to easily integrate the toolkit into their existing AI workflows.\n",
       "- The toolkit should receive positive feedback from users, indicating improved understanding and trust in AI models.\n",
       "\n",
       "## 11. Customer Analysis:\n",
       "The primary customers for this feature are data scientists, AI model developers, compliance officers, and stakeholders who require interpretability and explanation capabilities for their AI models. These customers are typically working in industries such as finance, healthcare, and legal, where transparency and accountability are crucial. The feature will be particularly valuable for organizations that need to comply with regulatory requirements or explain AI model decisions to end-users or auditors."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "display(Markdown(outputs[\"wandb\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "synap_labs_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
