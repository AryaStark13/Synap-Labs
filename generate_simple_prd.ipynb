{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate, load_prompt\n",
    "from langchain.agents import load_tools, initialize_agent\n",
    "import openai\n",
    "import os\n",
    "import wandb\n",
    "from wandb.integration.langchain import WandbTracer\n",
    "import json\n",
    "\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33marihantsheth\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\ariha\\Desktop\\Synap Labs\\wandb\\run-20230607_145401-uj84b0gm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/arihantsheth/generate_simple_prd/runs/uj84b0gm' target=\"_blank\">generate_multiple_prd_1</a></strong> to <a href='https://wandb.ai/arihantsheth/generate_simple_prd' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/arihantsheth/generate_simple_prd' target=\"_blank\">https://wandb.ai/arihantsheth/generate_simple_prd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/arihantsheth/generate_simple_prd/runs/uj84b0gm' target=\"_blank\">https://wandb.ai/arihantsheth/generate_simple_prd/runs/uj84b0gm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/arihantsheth/generate_simple_prd/runs/uj84b0gm?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x1ecaa148400>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    project=\"generate_simple_prd\",\n",
    "    config={\n",
    "        \"model\": \"gpt-3.5-turbo\",\n",
    "        \"temperature\": 0\n",
    "    },\n",
    "    entity=\"arihantsheth\",\n",
    "    name=\"generate_multiple_prd_1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "prompt_template = load_prompt(\"./generate_prd_template.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_input_variables = {\n",
    "    \"wandb\": dict(\n",
    "        company_name=\"Weights and Biases\",\n",
    "        company_desc=\"A leading AI startup specializing in experiment tracking, data versioning, hyperparameter tuning, and much more.\",\n",
    "        existing_feature_list=\"1. System and custom metrics logging\\n2. Real-time experiment visualization\\n3. Comparing different hyperparameter results\\n4. Automated sweeps over different hyperparameters\\n5. Shareability by creating reports\\n6. Data version Control\",\n",
    "        new_feature=\"Model Explainability Toolkit (MXT)\",\n",
    "        new_feature_desc=\"Enables users to interpret and explain the outputs and decision-making of their AI Models.\"\n",
    "    ),\n",
    "    \"langchain\": dict(\n",
    "        company_name=\"Langchain\",\n",
    "        company_desc=\"A young AI startup making it easier to use and connect Large Language Models (LLMs) to other tools such as Vector Database, Agents, Prompt Templates, and more.\",\n",
    "        existing_feature_list=\"1. Models: A suite of pretrained LLMs\\n2. Prompts: Templates for prompt engineering and prompt tuning\\n3. Memory: Ability to connect LLMs to vector databases\\n4. Indexes: Text splitters\\n5. Chains: Chain multiple prompts and LLMs together\\n6. Agents: Drives decision making processes using LLMs\",\n",
    "        new_feature=\"Model Training Wizard (MTW)\",\n",
    "        new_feature_desc=\" A user-friendly interface that guides users through the process of training their own custom language models. It would provide step-by-step instructions, dataset management tools, and performance evaluation metrics to help users create high-quality models tailored to their specific needs.\"\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = dict()\n",
    "for company in prompt_input_variables:\n",
    "    prompts[company] = prompt_template.format(**prompt_input_variables[company])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./company_prompts/prompt_inputs.json\", \"w\") as f:\n",
    "    json.dump(prompt_input_variables, f)\n",
    "\n",
    "with open(\"./company_prompts/prompts.json\", \"w\") as f:\n",
    "    json.dump(prompts, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating PRD for wandb...\n",
      "Generating PRD for langchain...\n"
     ]
    }
   ],
   "source": [
    "outputs = dict()\n",
    "\n",
    "for company in prompts:\n",
    "    print(f\"Generating PRD for {company}...\")\n",
    "    prompt = prompts[company]\n",
    "    \n",
    "    try:\n",
    "        output = llm(prompt, callbacks=[WandbTracer()])\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        output = f\"ERROR: {e}\"\n",
    "\n",
    "    outputs[company] = output\n",
    "    wandb.log({f\"{company}_prd\": output})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for company in outputs:\n",
    "    with open(f\"./generated_prds/{company}_prd.md\", \"w\") as f:\n",
    "        f.write(outputs[company])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Product Requirement Document (PRD)\n",
       "\n",
       "## 1. Project Overview\n",
       "The Model Explainability Toolkit (MXT) is a new feature that will be added to Weights and Biases, a leading AI startup specializing in experiment tracking, data versioning, hyperparameter tuning, and much more. The purpose of this project is to enable users to interpret and explain the outputs and decision-making of their AI models. This feature will help users gain insights into how their models work and make better decisions based on those insights.\n",
       "\n",
       "## 2. Project Scope\n",
       "The MXT feature will include the following:\n",
       "- Ability to explain the outputs and decision-making of AI models\n",
       "- Integration with existing Weights and Biases features\n",
       "- User-friendly interface for easy interpretation of model outputs\n",
       "- Compatibility with popular machine learning frameworks\n",
       "\n",
       "The following are excluded from the project scope:\n",
       "- Integration with non-popular machine learning frameworks\n",
       "- Support for non-AI models\n",
       "\n",
       "## 3. Functional Requirements\n",
       "The MXT feature should deliver the following functionalities:\n",
       "- Ability to generate explanations for model outputs\n",
       "- Ability to visualize the explanations in a user-friendly manner\n",
       "- Integration with existing Weights and Biases features\n",
       "- Compatibility with popular machine learning frameworks\n",
       "\n",
       "## 4. Non-functional Requirements\n",
       "The MXT feature should meet the following criteria:\n",
       "- Performance: The feature should not significantly impact the performance of the AI models.\n",
       "- Security: The feature should not compromise the security of the user's data.\n",
       "- Usability: The feature should be easy to use and understand.\n",
       "- Scalability: The feature should be able to handle large datasets and models.\n",
       "\n",
       "## 5. Use Cases\n",
       "The following are detailed scenarios that describe how users will interact with the MXT feature:\n",
       "- A user trains an AI model and wants to understand how the model is making its predictions.\n",
       "- A user wants to compare the explanations of different models to determine which model is better.\n",
       "- A user wants to share the explanations with their team or stakeholders.\n",
       "\n",
       "## 6. User Interface (UI) and User Experience (UX) Guidelines\n",
       "The MXT feature should adhere to the following design principles and requirements:\n",
       "- The UI should be intuitive and easy to use.\n",
       "- The UX should be consistent with the existing Weights and Biases features.\n",
       "- The explanations should be presented in a clear and understandable manner.\n",
       "\n",
       "## 7. Assumptions and Constraints\n",
       "The following factors or limitations may impact the development or implementation of the MXT feature:\n",
       "- The feature may not work with all machine learning frameworks.\n",
       "- The feature may require additional computational resources.\n",
       "\n",
       "## 8. Technical Requirements\n",
       "The MXT feature will require the following technologies, platforms, or infrastructure:\n",
       "- Integration with popular machine learning frameworks such as TensorFlow, PyTorch, and scikit-learn.\n",
       "- Additional computational resources such as GPUs or TPUs may be required.\n",
       "\n",
       "## 9. Timeline and Milestones\n",
       "The proposed schedule for the MXT feature is as follows:\n",
       "- Research and planning: 2 weeks\n",
       "- Development and testing: 8 weeks\n",
       "- Integration with existing Weights and Biases features: 2 weeks\n",
       "- User testing and feedback: 2 weeks\n",
       "- Final testing and release: 2 weeks\n",
       "\n",
       "## 10. Success Criteria\n",
       "The success of the MXT feature will be evaluated based on the following criteria:\n",
       "- User adoption and engagement\n",
       "- Positive feedback from users\n",
       "- Increased usage of Weights and Biases features\n",
       "\n",
       "## 11. Customer Analysis\n",
       "The MXT feature is targeted towards data scientists, machine learning engineers, and researchers who use AI models in their work. These users are looking for ways to gain insights into how their models work and make better decisions based on those insights. The MXT feature will help these users achieve those goals and improve the accuracy and reliability of their AI models."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "display(Markdown(llm_response))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "synap_labs_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
